{"posts":[{"title":"Introduction of Eulerian path","text":"Definition An Eulerian trial is a trial in a finite graph that visits every edge exactly once. An Eulerian circuit or Eulerian cycle is an Eulerian trail that starts and ends on the same vertex. Theorems and Corollaries For Undirected Graph G The sufficient requisite that undirected graph G exists Eulerian trial is that: G is a connected graph Only exist 2 (Eulerian trial) or 0 (Eulerian circuit) vertexes have odd degrees. Corollaries: (1) When only existing 2 vertexes, these 2 vertexes must be the endpoints of the Eulerian trial. (2) The sufficient requisite that graph G contains an Eulerian cycle is that there is no vertex having odd degrees. For Directed Graph G The sufficient requisite that directed graph G exists Eulerian trial is that: The base map of graph G is connected. At most one vertex has (out-degree)-(in-degree) = 1, at most one vertex has (in-degree)-(out-degree) = 1, every other vertex has equal in-degree and out-degree. Corollaries: (1) The start point is the vertex with (out-degree)-(in-degree) = 1. The end point is the vertex with (in-degree)-(out-degree) = 1. (2) Directed graph G exists Eulerian circle if and only if every vertex has equal in-degree and out-degree. How to find the Eulerian trial DFS Determine the existence of the Eulerian trial of graph G using the Eulerian theorem, and find the start point and the end point as mentioned above. Using DFS to iterate over every vertex ( every vertex is traversed once ). Record the traversed vertex when searching. Finally, we could get the Eulerian trial of graph G. 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849#include &lt;iostream&gt;#include &lt;algorithm&gt;#include &lt;vector&gt;#include &lt;unordered_map&gt;using namespace std;void dfs(unordered_map&lt;int, vector&lt;int&gt;&gt;&amp; neibors, int cur, vector&lt;int&gt;&amp; ans, vector&lt;bool&gt;&amp; visited) { for (int neibor: neibors[cur]) { if (!visited[neibor]) { visited[neibor] = true; dfs(neibors, neibor, ans, visited); } } ans.push_back(cur);}/* vertexes: n x 2 matrix, representing vertexes in graph G min: minimum value of the node max: maximum value of the node */vector&lt;int&gt; EulerianTrial(vector&lt;vector&lt;int&gt;&gt;&amp; vertexes, int min, int max) { int n = max-min+1; unordered_map&lt;int, vector&lt;int&gt;&gt; neibors; // Adjacency list vector&lt;int&gt; in(n), out(n); // record in degree and out degree vector&lt;bool&gt; visited(n, false); for (auto&amp; vertex:vertexes) { neibors[vertex[0]].push_back(vertex[1]); in[vertex[1]]++; out[vertex[0]]++; } bool have_fixed_start_point = false; vector&lt;int&gt; ans; for (int i=min; i&lt;=max; i++) { if (out[i]-in[i]==1) { have_fixed_start_point = true; dfs(neibors, i, ans, visited); // exist vertex with odd in-degree, which is the start point break; } } if (!have_fixed_start_point) { dfs(neibors, min, ans, visited); } reverse(ans.begin(), ans.end()); return ans;} Application A list of sticks with color on either end (ex. (cyan, violet)), and write an algorithm to find a sequence where each end of the stick is lined up with their corresponding color (ex. (cyan, violet) - (violet, red) - (red, blue)). Return the sequence if it exists, otherwise, return “impossible”. Analysis: We could treat the sticks as vertexes in graph G. The corresponding color is the nodes in graph G. Then the question could be transformed to “Please find the Eulerian trial in this graph”. Code: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354int N = 2000, Min, Max;vector&lt;int&gt; visited(N);vector&lt;int&gt; ans;void dfs(vector&lt;vector&lt;int&gt;&gt;&amp; mp, int cur) { for (int i=Min; i&lt;=Max; i++) { if (mp[cur][i]) { mp[cur][i]--; mp[i][cur]--; dfs(mp, i); } } ans.push_back(cur);}void getSticks(vector&lt;vector&lt;int&gt;&gt;&amp; sticks) { vector&lt;vector&lt;int&gt;&gt; mp(N, vector&lt;int&gt;(N, 0)); Min = INT_MAX; Max = INT_MIN; vector&lt;int&gt; degrees(N); for (auto stick: sticks) { mp[stick[0]][stick[1]]++; mp[stick[1]][stick[0]]++; Min = min(Min, min(stick[0], stick[1])); Max = max(Max, max(stick[0], stick[1])); degrees[stick[0]]++; degrees[stick[1]]++; } bool flag = false; for (int i=Min; i&lt;=Max; i++) { if (degrees[i]%2) { flag = true; dfs(mp, i); break; } } if (!flag) { dfs(mp, Min); } reverse(ans.begin(), ans.end());}int main() { vector&lt;vector&lt;int&gt;&gt; sticks = {{1,2}, {2,1}, {1,3}, {3,4}}; getSticks(sticks); for (int i: ans) { cout &lt;&lt; i &lt;&lt; &quot; &quot;; } cout &lt;&lt; endl;}","link":"/2022/02/19/Introduction-of-Eluerian-path/"},{"title":"Learning Notes: Google File System","text":"https://static.googleusercontent.com/media/research.google.com/zh-CN//archive/gfs-sosp2003.pdf Google File System is a scalable distributed file system for large distributed data-intensive applications. Characteristic Fault tolerance; Inexpensive commodity hardware; Supporting distributed applications. Key Observations 1. Component failures are the norm rather than the exception.Constant monitoring, error detection, fault tolerance, and automatic recovery must be integral to the system. 2. Files are huge by traditional standards. Multi-GB files are common.Design assumptions and parameters such as I/O operation and block size have to be revisited. 3. Most files are mutated by appending new data rather than overwriting existing dataAppending becomes the focus of performance optimization and atomicity guarantees. 4. Co-designing the applications and the file system API benefits the overall system by increasing our flexibility.The related consistency model vastly simplifies the file system without imposing an onerous burden on the applications. Introduced an atomic append operation so that multiple clients can append concurrently to a file without extra synchronization between them. Assumptions System often fails System stores a modest number of large files Read: Large streaming reads Small random reads Many large, sequential writes that append data to files Multiple clients concurrently append to the same file High sustained bandwidth is more important than low latency Architecture A GFS cluster consists of a single master and multiple chunkservers and is accessed by multiple clients. Files are divided into fixed-size chunks. Each chunk is replicated on multiple chunkservers. The master maintains all file system metadata. Clients interact with the master for metadata operations, but all data-bearing communication goes directly to the chunkservers. Neither the client nor the chunk server caches file data. Client caches offer little benefit because most applications stream through huge files or have working sets too large to be cached. Data Flow Utilize each machine’s network bandwidth: The data is pushed linearly along a chain of chunk servers rather than distributed in some other topology. Avoid network bottlenecks and high-latency links as much as possible: Each machine forwards the data to the “closest” machine in the network topology that has not received it. Minimize latency: Pipelining the data transfer over TCP connections as using a switched network with full-duplex links. The ideal elapsed time for transferring B bytes to R replicas is B/T + RL where T is the network throughput and L is the latency to transfer bytes between two machines. MasterMaintain: File and chunk namespaces, access control information, the mapping from files to chunks, and the current locations of chunks. Control: System-wide activities such as chunk lease management, garbage collection of orphaned chunks, and chunk migration between chunkservers. Single Server Advantages: Simplify the design and enable the master to make sophisticated chunk placement and replication decisions using global knowledge. No Single Server bottleneck: (1) Clients never ask for files or write file data from the master. (2) Clients cache this information for a limited time. In this way, they could interact with chunkservers directly. Chunk Size64 MB. Lazy space allocation avoids wasting space due to internal fragmentation. Large Chunk Size Advantages: (1) Reduce the client’s need to interact with the master. (2) Client could perform many operations on a given chunk, reducing network overhead by keeping a persistent TCP. (3) Reduce master meta data size. In this way, meta data could be put into the memory of the master. Large Chunk Size Disadvantages: Small file size means a small number of chunks, perhaps just one. The chunkservers storing those chunks may become hot spots if many clients are accessing the same file. The solution is: (1) store this with a higher replication factor, (2) stagger app start times. Meta Data File and chunk namespaces Mapping from files to chunks Locations of each chunk’s replicas. All metadata is kept in the master’s memory. The first two types are also kept persistent by logging mutations to an operation log stored on the master’s local disk and replicated on remote machines. Store in Memory Advantages: It is easy and efficient for the master to periodically scan through its entire state in the background. (Chunk garbage collection, re-replication in the presence of chunkserver failures, and chunk migration to balance load and disk space usage across chunkservers) What if memory limitation? The master maintains less than 64 bytes of metadata for each 64 MB chunk. The file namespace data typically requires less than 64 bytes per file because it stores file names compactly using prefix compression. Chunk LocationNot persistent record. The master polls at startup. Updated: The master controls all chunk placement and monitors chunkserver status with regular HeartBeat messages. Operation LogHistorical records of critical metadata changes. Logical time line that defines the order of concurrent operations. (1) Replicate it on multiple remote machines. (2) Respond to a client operation only after flushing the corresponding log record to disk both locally and remotely. Minimize startup time: Keep the log small. The master checkpoints its state whenever the log grows beyond a certain size so that it can recover by loading the latest checkpoint from local disk and replying only the limited number of log records after that. Consistency ModelFile namespace mutations are atomic. Namespace locking guarantees atomicity and correctness. Defined: Consistent and clients will see what the mutation writes in its entry. Consistent but undefined: All clients will always see the same data, but it may not reflect what anyone mutation has written. After a sequence of successful mutations, the mutated file region is guaranteed to be defined and contain the data written by the last mutation. ​ (a) applying mutations to a chunk in the same order on all its replicas. ​ (b) Using chunk version numbers to detect any replica that has become stale because it has missed mutations while its chunkserver was down. ❌ Stale replica: ​ (a) The cache entry has a timeout and the next open of the file, which purges from the cache all chunk information for the file. ​ (b) As most of the files are append-only, a stale replica usually returns a premature end of chunk rather than outdated data. ❌ Component failures: GFS identifies failed chunkservers by regular handshakes between master and all chunkservers and detects data corruption by checksumming. Implications for Applications Appends rather than overwrites Checkpoints include application-level checksums Writing self-validation Self-identifying records Atomic Record Appends In a record append, the client specifies only the data. GFS appends it to the file at least once atomically. Similar to the data flow, except if append cause the chunk exceeds maximum size (64 MB). Snapshot A copy of a file or a directory tree almost instantaneously. Use standard copy-on-write techniques to implement snapshots. (1) The master revokes any outstanding leases on the chunks in the files it is about to snapshot. (2) The master logs the operation to disk. It then applies this log record to its in-memory state by duplicating the metadata for the source file or directory tree. The newly created snapshot files point to the same chunks as the source files. (3) The client wants to write to Chunk C after snapshot operation. It sends a request to the master to find the lease handler. The master checks that the reference count for chunk C is greater than one. It would pick a new chunk handle. Master Operations Allow multiple operations to be active and use locks over regions of the namespace to ensure proper serialization. Use lookup table: fullPathNames -&gt; metaData Read lock: Prevent the directory from being deleted, renamed, or snapshotted. Write lock: Prevent creating a file with the same name. 12/d1/d2/.../dn/ leaf read-locks write-locks Chunk ReplicasCreation Place on chunkservers with below-average disk space utilization. Limit the number of “recent” creations on each chunkserver. Spend replicas of a chunk across racks. Re-replicatesThe master re-replicates a chunk as soon as the number of available replicas falls below a user-specific goal. A chunkserver becomes unavailable. Replica corrupted. One of the disks is disabled. Replication goal is increased. Priority: (1) How far to the goal (2) is there any chunk that is blocking client progress. Stale Replica DetectionMaster maintains a chunk version number to distinguish between up-to-date and stale replicas. After granting a new lease, the master increases the chunk version number and informs the up-to-date replicas. After the chunkserver restarts and reports its set of chunks and associated version number. If the master sees a version number greater than the one in its records, the master assumes that it failed when granting the lease.","link":"/2022/03/12/Learning-Notes-Google-File-System/"},{"title":"GRU LSTM 综述","text":"总结于Deeplearning.ai 1. 符号表示 符号 含义 $ x^{(t)} $ 位置$ t $的单词的特征表示 $ y^{(t)} $ 第$ i $个句子位置t应输出的数据，即目标值 (图中未标出) $ T_x $ 输入序列的长度 $ T_y$ 出序列的长度 $ a^{(t)} $ 来自第$ t $个时间步的信息 $ W_{ax} $ 从$ x^{(t)} $到隐藏层的连接的一系列参数 $ W_{aa},\\ b_a $ 激活值$ a^{(t)} $到下一个隐层的参数 $ W^{ya} $ 输出值参数 (图中未画出) $ \\hat{y}^{(t)} $ 位置t的输出数据 在表示单词时，可以使用one-hot表示法进行表示，one-hot列向量中只有一行为1，其余为0，这一行为这个列向量表示的单词。当遇见不属于词表的单词时，可以使用的伪单词的列向量进行标记。 循环神经网络参数在每个时间步中共享，因此上图显示的是数据随时间的流向，实际输出数据重新进入原RNN cell，因此上图三个cell中的$ W_{aa}$和$ W_{ax} $是相同的。 2. 循环神经网络模型(1) 为什么使用循环网络模型？ 每个输入与输出数据可以具有不同的长度，因此无法使用传统神经网络结构进行计算； 简单的神经网络结构无法共享从文本不同位置学到的特征。文本识别可以类比卷积，在句子中不同位置出现的单词应当能够自动识别。使用传统网络结构一方面无法捕捉这种序列内部的位置信息，另一方面由于使用one-hot编码，因此每个单词乘字典维度为输入的数量，参数过多不适合训练。 (2) 神经网络结构 以句子作为输入为例，循环网络模型首先输入第一个单词的特征表示$ x^{(1)} $，并计算得到结果$ y^{(1)} $，之后读取第二个单词的特征表示$ x^{(2)} $，只是为了获得序列位置信息，网络结构还需要输入来自第一个时间步的信息，具体而言即时间步1的激活值$ a^{(1)} $会传入时间步2，与$ x^{(2)} $共同计算得到第二个时间步的输出$ y^{(2)} $，以此类推。 在开始整个流程时，需要构造一个激活值$ a^{(0)} $，这个值将与第一个单词的特征表示$ x^{(1)} $共同参与计算第一个时间步的输出值$ y^{(1)} $，一般使用零向量，也可以随机使用其他方法进行初始化。 正向传播在正向传播过程的第$ t $个时间步中，先输入$ a^{(t-1)} $和$ x^{(t)} $，分别和各自的参数$ W_{aa} $和$ W_{ax} $相乘并相加，之后经过激活函数后得到激活值$ a^{(t)} $，成为下一个时间步的输入。同时计算得到这个时间步的输出值$ y^{(t)} $，即：$$a^{(t)}=g_1(W_{aa}a^{(t-1)}+W_{ax}x^{(t)}+b_a),$$ $$\\hat{y}^{(t)}=g_2(W_{ya}a^{(t)}+b_y).$$ 循环神经网络的激活函数经常选用tanh，也可以视具体情况使用其他激活函数。选用哪种激活函数取决于实现什么功能，如果是二分类问题就可以使用sigmoid，k分类的话使用softmax是更好的选择。在上图中有两个激活函数，也就是式子中的$ g_1() $和$ g_2() $，上文所指的是$ g_2() $。 上文中的公式可以进行简化，我们定义$ W_a $为$ W_{aa} $和$ W_{ax} $并列放置，即上图左侧两个矩形构成的矩阵，然后将$ a^{(t-1)} $和$ x^{(t)} $纵向放置，构成一个矩阵，记为$ [a^{(t-1)},x^{(t)}] $，因此可以将公式改写为：$$a^{(t)}=g_1(W_a[a^{(t-1)},x^{(t)}]+b_a),$$ $$\\hat{y}^{(t)}=g_2(W_{ya}a^{(t)}+b_y).$$ 反向传播反向传播的代价函数可以使用softmax损失函数： $$ L^{(t)}(\\hat{y}^{(t)},y^{(t)})=-\\sum_i{y_i^{(t)}log\\hat{y}_i^{(t)}}. $$ 这个损失函数对应的序列中的一个具体的词，然后我们定义整个序列的损失函数，将$ L $定义为：$$L(\\hat{y},y)=\\sum_{t=1}^{T_x}L^{(t)}(\\hat{y}^{(t)},y^{(t)}).$$在这个计算中，首先计算各个时间步的损失函数结果，然后将他们加起来，得到最后的损失。这种计算损失的方式称为backpropagation through time。 3. 循环神经网络的梯度消失基本的RNN算法存在很大的问题。举一个语言模型的例子，当看到句子”The cat, which already ate ……, was full.”，句子的前后应当一致，即cat为单数，对应was。这个句子有长期的依赖，最前面的单词对后面的单词有影响。而传统的RNN算法不擅长捕获这种长期的影响。 具体的原因类似网络层数加深时的梯度消失，在经过多个时间步后并反向传播，输出$ \\hat{y} $的梯度很难传播回去，因此很难影响前面层的计算。这说明，很难让一个神经网络意识到它需要记住单词是单数形式还是复数形式。无论后面单词的预测正确与否，这个错误都很难影响到前面的参数。 当然，也有可能遇到梯度爆炸的问题，模型没有收敛的趋势，而出现了很多NaN，这个时候可以使用梯度修剪，通过监测梯度向量，如果大于某个阈值，则缩放梯度向量，保证它不会太大。 4. GRU单元Gated Recurrent Unit (GRU) 门控制单元改变了RNN的隐藏层，使其更适合捕捉深层的特征，改善了梯度消失问题。 当从左往右读一个句子时，GRU单元使用一个新的变量，称其为$c$，代表细胞（cell），即记忆细胞。记忆细胞可以提供记忆的能力，即在后面的时间步中记忆前面时间步的信息。在时间$ t $处，有记忆细胞$ c^{(t)}=a^{(t)} $。它们的值是一样的，不同的名称是为了区分激活值和记忆细胞。 在每一个时间步中，我们需要计算一个候选值$ \\widetilde{c}^{(t)}=tanh(W_c[c^{(t-1)},x^{(t)}]+b_c) $，这个候选值和$ c^{(t)} $会被每个时间步选择使用哪一个。 GRU中最重要的是我们使用了一个门$ \\Gamma_u $，其中$ \\Gamma $代表门，$ u $表示更新门，这是一个0到1之间的值。这个值的计算为：$$\\Gamma_u=\\delta(W_u[c^{(t-1)},x^{(t)}]+b_u).$$因此，这个值是通过将计算结果带入sigmoid函数得到的。sigmoid使得大多数情况下，$ \\Gamma_u $的输出基本上非常接近0或1。门的作用是控制是否需要更新记忆细胞的值。以上文的单数句子为例，GRU单元会记住这个句子使用了单数，从而在后面生成单词时选择其单数形式。可以通过下列的式子达到对句子中特定时间点的记忆： $$ c^{(t)}=\\Gamma_u*\\widetilde{c}^{(t)}+(1-\\Gamma_u)*c^{(t-1)}. $$ 在这个式子中，如果激活值的维度为100维，那么$ c^{(t-1)} $，$ \\widetilde{c}^{(t)} $和$ \\Gamma_u $均为100维，因此上式中的$ * $为元素对应相乘，而不是矩阵乘法。 从这个式子中我们可以看到，当$\\Gamma_u$的值接近1时，此时时间细胞会主要选择这个时间点计算的结果并存储在记忆细胞中，而当$ \\Gamma_u $趋近于0时，$ c^{(t)} $会选择保留上一时间点的记忆$ c^{(t-1)} $，从而达到记忆某个时间点的目的。由于$ \\Gamma_u $为一个向量，因此GRU单元可以选择保存这个向量中的部分值而更新其他值以达到保存部分特征并更新其他特征的目的。 上图绘制了一个简易的GRU单元第t个时间步中计算过程为： （1）输入上一个时间步的记忆细胞$ c^{(t-1)} $和这个时间步的输入$ x^{(t)} $，使用tanh函数计算得到候选值$ \\widetilde{c}^{(t)} $； （2）同样输入上一个时间步的记忆细胞$ c^{(t-1)} $和这个时间步的输入$ x^{(t)} $，使用sigmoid函数计算得到更新门值$ \\Gamma_u $； （3）进行记忆细胞值的更新。输入上一个时间步的记忆细胞$ c^{(t-1)} $和这个时间步的输入$ x^{(t)} $，以及上一步计算得到的更新门值$ \\Gamma_u $，计算得到新的记忆细胞值$ c^{(t)} $； （4）输入新的记忆细胞值$ c^{(t)} $，通过softmax函数生成这个时间步的输出$ \\hat{y}^{(t)} $。 由于现在这些门很容易取到0值，因此更新的式子就会变成$ c^{(t)}=c^{(t-1)} $，这非常有利于维持细胞的值，因此就不会有梯度消失的问题了，因此允许神经网络运行在非常庞大的依赖词上。 对于完整的GRU单元，我们需要在计算记忆细胞的候选值时加入一个新的项$ \\Gamma_r $，这个项是一个新的门，其中的$ r $可以理解为相关性(relevance)，这个门告诉了计算出的下一个$ c^{(t)} $的候选值$ \\widetilde{c}^{(t)} $跟$ c^{(t-1)} $有多大的相关性。计算相关门的值需要一个新的参数矩阵$ W_r $，$ \\Gamma_r=\\sigma(W_r[c^{(t-1)},x^{(t)}]+b_r) $。因此完整的GRU单元的公式如下： $$ \\widetilde{c}^{(t)}=tanh(W_c[\\Gamma_r*c^{(t-1)},x^{(t)}]+b_c), $$ $$ \\Gamma_u=\\sigma(W_u[c^{(t-1)},x^{(t)}]+b_u), $$ $$ \\Gamma_r=\\sigma(W_r[c^{(t-1)},x^{(t)}]+b_r), $$ $$ c^{(t)}=\\Gamma_u*\\widetilde{c}^{(t)}+(1-\\Gamma_u)*c^{(t-1)}. $$ 5. LSTM单元LSTM相比于GRU，更加强大和通用。 上面为LSTM和GRU的主要式子对比。相比GRU，LSTM没有相关门$ \\Gamma_r $，同时激活值$a^{(t)}$不等于记忆细胞值$ c^{(t)} $。像以前一样，我们有一个更新门$ \\Gamma_u $和表示更新的参数$ W_u $，$ \\Gamma_u=\\sigma(W_u[a^{(t-1)},x^{(t)}]+b_u) $，即上图中1。LSTM的一个新特性是不止有更新门控制，在计算新的记忆细胞值时，LSTM使用两个门$ \\Gamma_u $和$ \\Gamma_f $来控制，而不是仅使用$ \\Gamma_u $来控制（如图2，3）。其中$ \\Gamma_f $为遗忘门，$ \\Gamma_f=\\sigma(W_f[a^{(t-1)},x^{(t)}]+b_f) $。还有一个新的输出门$ \\Gamma_o=\\sigma(W_o[a^{(t-1)},x^{(t)}]+b_o) $。 于是，记忆细胞的更新值$ c^{(t)}=\\Gamma_u*\\widetilde{c}^{(t)}+\\Gamma_f*c^{(t-1)} $。最后，$ a^{(t)}=c^{(t)} $的式子变成了$ a^{(t)}=\\Gamma_o*c^{(t)} $。 LSTM在时间步t的计算过程如下： （1）输入激活值$ a^{(t-1)} $和输入数据$ x^{(t)} $，带入forget gate、update gate、output gate公式，计算得到值$ \\Gamma_f $、$ \\Gamma_u $和$ \\Gamma_o $； （2）输入激活值$ a^{(t-1)} $和输入数据$ x^{(t)} $，带入tanh公式，得到候选值$ \\widetilde{c}^{(t)} $； （3）利用 (1) 中计算的得到的$ \\Gamma_f $、$ \\Gamma_u $，（2）中计算得到的候选值$ \\widetilde{c}^{(t)} $，以及上一个时间步记忆单元的值$ c^{(t-1)} $计算得到新的记忆单元值$ c^{(t)} $； （4）输入输出门$ \\Gamma_o $的值和 (3) 中计算得到的本时间步的记忆单元的值计算得到新的激活值$ a^{(t)} $； （5）将新的激活值送入激活函数（例如softmax），得到输出值$ y^{(t)} $。 LSTM最常用的版本的门值不仅取决于$ a^{(t-1)} $和$x^{(t)}$，也可以偷窥一下$ c^{(t-1)} $的值，这叫做peephole connection。因此在计算三个门$ \\Gamma_f $、$ \\Gamma_u $和$ \\Gamma_o $时，加入$ c^{(t-1)} $计算。实际上，$ c^{(t-1)} $中的每一个元素仅能硬系那个处于同一维度的门值，不能硬系那个所有元素，因此偷窥孔可以称为是一对一的。","link":"/2020/01/22/Sequence%20Models%20%E7%BB%BC%E8%BF%B0/"},{"title":"图像自动生成描述","text":"总结于：http://cs.stanford.edu/people/karpathy/main.pdf 1. 目的长期目标：计算机理解知识可以总结为通过两个渠道：（1）通过物理媒介：基于传感器和现实世界的物体及交互；（2）通过互联网：主要通过互联网的自然语言。研究图像描述生成即是研究视觉和自然语言的联系，通过构建计算机对视觉和语言的联系，可以构建更加智能的系统，例如根据网络语言学习新知识、理解知识并在现实生活中作出反应。 短期目标：（1）由于复杂的序列语言可以表示名词、动词、形容词等，因此可以泛化目前一系列相对独立的cv领域，例如目标分类、动作识别等；（2）由于用户对自然语言掌握程度比独立词语更好，因此更符合用户需要，例如用户在搜寻照片时，通过一段文字来搜寻比通过关键字搜索更加符合用户习惯。 2. 挑战 评估困难：在图像分类任务中，可以通过比较分类结果的正确性来达到评估目的，但是很难根据得到的自然语言语句结果得到精确的评估结果。通过使用一些最先进的自动评估方法，可以达到和人类评估类似的评估结果； 模型分离：将视觉识别任务和语言建模任务结合在一起的研究中，很容易将其分解为两个部分进行单独考虑，即图像处理和自然语言生成两个部分，这与传统模型类似，只是做了合并。可以通过端到端的方式进行训练，仅通过单独的模型达到目的，而不需要对两个方面进行单独的考虑。 3. 相关工作4. 数据源 链接:https://pan.baidu.com/s/1YNGB3ANAwxOsv34NscJWcQ 密码:502r 数据集具体介绍：https://arxiv.org/abs/1711.06475 数据源为AI Challenger全球AI挑战赛数据集，数据集中包含30万张图片和150万句中文描述，其中每张图片对应5句中文描述。 Tipscaption 和 description 的区别？ caption：主要关注图片外的隐性信息，如拍摄时间、地点、状态等； description：主要关注图片本身内容的描述。 5. 实现过程(1) 模型介绍使用 Multimodal RNN language model 来实现生成图片描述。在图片描述生成任务中，首先使用CNN提取图像特征，然后将图像特征和每一步预测的当前词送入RNN结构中，即下图中的结构： 我们可以用下面的公式表示上图的关系：$$ b_V = W_{hi}[CNN_{\\theta_c}(I)], $$$$ h_t = f(W_{hx}x_t+W_{hh}h_{t-1}+b_h+\\delta{t=1}\\bigodot b_v), $$$$ y_t=W_{oh}h_t+b_o. $$ 其中, W、$ b_h $、$ b_o $为要学习的参数，$ CNN_{\\theta_c}(I) $为CNN的最后一个隐层输出（全连接层前一层），$ \\delta{t=1}\\bigodot b_v $为delta表达式，表示仅当t=1时带入$ b_v $计算（这里的原因是原文实验验证后得到，仅把图像内容作为RNN的第一层输入效果比将图像作为RNN每层输入效果好）。因此RNN中在每一步中传递的信息为图像信息和文本信息，要实现这一效果，我们需要证明虽然图像信息仅在RNN第一步传入，但可以将其传递给后面每一步。当$ W_{hh} $为[1, 0, 0, …]、且$ W_{hx} $的第一行为全0时，可以将完整的传递图像信息传递给下一层。在RNN中，第一步我们可以传入指定的START词向量，在生成完成后回得到END词向量。在反向传播的过程中，为了方便并行运算，可以让RNN在生成END词向量后的每一个时间步都生成END。在测试过程中，可以使用beam search方法提升算法的准确度，生成更关注图像全局信息的语句。 (2) 模型优化在训练过程中我们会发现模型较难优化，这是因为不同词语之间的频率差异过于悬殊，例如END会出现在每一个句子中，而牙刷可能在训练集中一共出现五次。为了缓解数据集中数据数量差异问题，我们可以使用RMSprop、SGD、SGD+Momentum、Adam等方式对参数更新进行优化。实验验证RMSprop和Adam效果较好。当在训练前显试初始化字典中所有词的偏向，可以带来较快的收敛速度。实验结果也证明，使用word2vec向量初始化单词向量和随机初始化单词向量达到的效果基本类似。 (3) 评价标准生成文本的评价标准使用BLEU score，BLEU用于评价机器翻译的充分性和流畅度。其中需要指定n-gram，即比较生成文本中长度为n的文本片段和参考文本中的长度为n的文本片段的匹配片段的个数，匹配片段个数越多，生成文本效果越好。BLEU的计算公式使用Brevity Penalty值评价翻译的完整度，公式如下，其中c为待评价语句长度，r为参考语句长度： $$ BP=\\begin{cases} 1, \\quad c>r \\\\[2ex] e^{(1-r/c)}, \\quad c \\leq r. \\end{cases} $$ BLEU值的计算公式为： $$ BLEU=BP\\cdot exp(\\sum_{n=1}^{N}w_nlogp_n). $$ BLEU值越大越好。 6. 一些改进(1)模型介绍在上一节，使用了Multimodal RNN实现了对图像描述的生成，但这个方面有一定的局限性：对于比较复杂的图像，上面的结构仅能生成一句较为粗略的描述，我们可以通过改进网络结构生成多句对同一图像不同关注点的描述，下图为文献中一个较为形象的解释： 在几年前，研究人员较好地实现了对于图像的单标签分类。在近几年，研究领域主要集中在两个方面：（1）检测单张图片的多个物体区域并分类；（2）增加生成标签语句的复杂度，使其较为完整地描述图像内容。然而这两个研究方向处于孤立的状态，下面我们将介绍如何实现对于复杂图片的密集描述模型，该模型的示意图如下图所示： 网络以图像为输入，通过CNN生成图像的多个特征数据。这些特征数据通过Localization Layer提取特征区域并使用双线性插值作为激活函数，之后通过RNN生成连贯的语句。 (2) 模型结构 卷积网络 使用VGG-16，共有13层3x3卷积和5层2x2最大值池化，在实验中去掉了最后一层池化，因此输入的图像数据为$ 3\\times W\\times H $，输出的特征数据维度为$ C\\times W’\\times H’ $，其中$ C=512, W’=\\lfloor \\frac{W}{16} \\rfloor, H’=\\frac{H}{16} $. 这些数据被送入Localization Layer进行下一步处理。 全卷积Localization Layer Localization Layer 以图像的特征数据为输入，得到图片中的兴趣空间区域并将这些空间区域以定长的特征表示出来。该层模型以Faster R-CNN为基础，并将RoI采样更换为双线性差值，使得模型可以利用生成的区域坐标反向传播更新参数。这一修改也使得兴趣空间区域不一定是矩形，可以是多边形。 输入/输出： Localization Layer接受大小为$ C \\times W’\\times H’ $，然后会选出其中B个兴趣区域，之后计算并返回结果，返回结果包括： ​ (1) 区域坐标：同一图像的一组区域坐标，维度为$ B\\times 4 $, 分别为中心点$ (x_a, y_a) $，宽$ w_a $和高$ h_a $； ​ (2) 区域得分：图片区域的得分向量，具有高置信度分数的区域更可能对应于真实的感兴趣区域，维度为$ B\\times 1 $; ​ (3) 区域特征：各个区域图像特征的矩阵，大小为$ B\\times C\\times X\\times Y $，因此每一个区域被表示为在$ X\\times Y $区域下的C维特征，实验中$ X, Y, C $分别为(7, 7, 512)； 卷积锚： Localization Layer不是直接从原图像上寻找候选区域，而是通过在缩放后的信息中生成图像区域矩形框的位置和为物体的置信得分。在Localization Layer中，针对每幅图像，遍历各个锚点，并使用计算k个不同宽高比（类似于多尺度方法）的锚框的置信得分。模型中将输入的特征传入有256个滤波器的3x3卷积中，之后通过一个非线性层和有5k个滤波器的1x1卷积。因此输出为$ 5k\\times W’ \\times H’ $。其中，一个通道 $ 5k\\times W’ \\times H’$表示锚框的置信得分，其余4个通道为用于更新卷积锚的偏移量。 边框采样： 在选择卷积候选区域的过程中我们使用了特征图上每一个关键点的k个不同大小的候选区域，因此对于大小为$ W’\\times H’ $的特征图像，其生成置信得分的维度为$ k\\times W’\\times H’ $。由于这个数量较大，因此考虑对边框进行采样。采样的方式在训练和测试过程中有所不同。 在训练中，我们共采样B=256个边框，其中最多1/2为正向区域（Positive regions），其余为负向区域（Negative regions）。当一个候选区域置信得分的Intersection over Union (IoU) 值大于等于0.7，它就被称为一个正向区域；相反，当其IoU值小于0.3，其为一个负向区域。在实验中，采样的小批梯度采样包括$ B_P&lt;B/2 $的正向区域和$ B_N=B-B_P $的负向区域。 在测试过程中，我们使用非极大值抑制（NMS）来选择$ B=300 $个得分最高的边框。NMS的原理是通过对所有边框得分进行排序，保留最高的分数，而与得分最高的边框重合面积（IOU）超过阈值的边框则删除。使用NMS并不是一个好的方法，因为在训练中和测试中使用了不同的采样方式，但是设计一个NMS神经网络或者使用其他通用的可微采样方法更为困难。 边框回归： 在上文我们求出了卷积锚，之后我们还需要将卷积锚还原为候选区域，给定锚框的中心$ (X_a, y_a) $，宽$ w_a $和高$ h_a $，模型可以输出归一化后的偏移量和对数空间的变化量$ (t_x, t_y, t_w, t_h) $，因此输出区域的中心$ (x, y) $和长宽$ (w, h) $的计算公式为： $$ x=x_a+t_xw_a\\\\ y=y_a+t_yh_a\\\\ w=w_aexp(t_w)\\\\ h=h_aexp(h_w). $$ 当模型输出全0时，锚框坐标及大小完全等于候选区域的坐标和大小，符合实际情况。 双线性插值： 经过采样后，我们得到了宽高比不同的多个候选区域，为了下一步送入识别网络和RNN，需要统一这些候选区域数据的维度。 Fast R-CNN使用了RoI池化层，将$ W’\\times H’ $的候选区域分割为$ X\\times Y$个网格，然后利用最大层池化得到$ X\\times Y $的输出特征。这个方法的输入为卷积特征和候选区域的坐标，但是其在训练时只能更新卷积特征，无法更新候选区域的坐标，因此对这个方面进行了改进。 在论文中，使用了双线性插值来生成$ X\\times Y $的输出特征数据，以实现对卷积特征和候选区域坐标的同时更新。我们的目的是将维度为$ C\\times W’\\times H’ $的输入特征$ U $生成输出特征映射$V$，其维度为$ C\\times X\\times Y $。双线性插值分为一下 个步骤： （1）计算输出特征$V$的每一个坐标点在输入特征的映射坐标点。这里计算的原因是双线性插值需要计算映射坐标到周围坐标的距离。这里计算得到的坐标不一定是整数，因此并不是实际的坐标，只是用于中间计算。假设我们正在计算输出特征$V$中一点$(c,x_{i,j}^v,y_{i,j}^v)$到输入特征$U$的映射点$(c,x_{i,j},y_{i,j})$的值，其公式为： $$ x_{i,j}=\\frac{x_{i,j}^v}{X}\\cdot W'\\\\ y_{i,j}=\\frac{y_{i,j}^v}{Y}\\cdot H'. $$ 得到映射点坐标后，设双线性采样的核函数为$k$，使用下面的公式我们就可以计算输入特征$U$到输出特征$V$的特征映射： $$ V_{c,i,j}=\\sum_{i'=1}^W'\\sum_{j'=1}^{H'}U_{c,i',j'}k(i'-x_{i,j})k(j'-y_{i,j})\\\\ k(d)=max(0,1-|d|). $$ 实际计算时我们会发现，参与计算的输入特征的特征点为计算的到的映射点坐标周围坐标值。计算后我们就可以得到一个$B\\times C\\times X\\times Y$的输出，这个输出特征即为Localization Layer的输出。 识别网络 识别网络是一个全连接网络，处理Localization Layer的输出，再最后一次调整并筛选候选区域，生成$B\\times D$的矩阵作为RNN的输入，其中$D=4096$，为每一个最终候选区域特征的向量表示维度。识别网络会调整候选区域的位置及得分，使用类似边框回归的方式更新候选区域位置。 RNN语言模型 使用LSTM实现文本的生成。在训练过程中，我们使用$T+2$个的词向量进行训练，即$x_{-1},x_0,x_1,…,x_T$。其中，$x_{-1}$表示候选区域特征的编码结果，在识别网络中，我们得到了各个候选区域的特征表示，之后通过一个linear layer和ReLU非线性函数，可以得到候选区域所有特征的编码结果。$x_0$为特殊的START编码标识。$x_1,…,x_T$编码了描述当前图片的每个词的词向量，以及最终的特殊END标识。 在测试时我们使用图像特征$x_{-1}$和START特殊标识作为输入，之后在每一个时间步生成下一个最可能的单词，之后送入RNN中继续下一个时间步，直到生成END标识。 (3) 损失函数损失函数由五项组成。在Localization Layer和识别网络中，都计算了候选区域的坐标和得分，这两个地方都使用了binary logistic losses更新得分，使用smooth L1 loss更新候选区域坐标。最后，在RNN的每一个时间步中使用cross-entropy更新RNN参数。所有的损失函数都依照批的大小和RNN中序列的长度进行了归一化。 Smooth L1 loss: $$ Smooth\\ L1=\\begin{cases} 0.5x^2,&|x|","link":"/2020/01/17/%E5%9B%BE%E5%83%8F%E6%8F%8F%E8%BF%B0%E8%87%AA%E5%8A%A8%E7%94%9F%E6%88%90%E7%BB%BC%E8%BF%B0/"},{"title":"图片生成文本描述","text":"https://www.jiqizhixin.com/articles/2017-11-15-2 1. 传统方法生成描述模板: 基于目标检测和属性发现（attribute discovery）的结果进行填充；数据库检索相似图像 2. 模型特征提取模型用作特征提取子模型的通常是深度卷积神经网络（CNN）。这种网络可以在图像描述数据集中的图像上直接训练。 或者可以使用预训练的模型（比如用于图像分类的当前最佳的模型），或者也可以使用混合方法，即使用预训练的模型并根据实际问题进行微调。 使用为 ILSVRC 挑战赛在 ImageNet 数据集上开发的表现最好的模型是很常见的做法，比如 Oxford Vision Geometry Group 模型，简称 VGG。 语言模型对于图像描述，语言模型这种神经网络可以基于网络提取出的特征预测描述中的词序列并根据已经生成的词构建描述。 常用的方法是使用循环神经网络作为语言模型，比如长短期记忆网络（LSTM）。每个输出时间步骤都会在序列中生成一个新词。 然后每个生成的词都会使用一个词嵌入（比如 word2vec）进行编码，该编码会作为输入被传递给解码器以生成后续的词。 对该模型的一种改进方法是为输出序列收集词在词汇库中的概率分布并搜索它以生成多个可能的描述。这些描述可以根据似然（likelihood）进行评分和排序。常见的方式是使用波束搜索（Beam Search）进行这种搜索。 语言模型可以使用从图像数据集提取出的预计算的特征单独训练得到；也可以使用特征提取网络或某些组合方法来联合训练得到。 编码器-解码器这种架构原本是为机器翻译开发的，其中输入的序列（比如法语）会被一个编码器网络编码成固定长度的向量。然后一个分立的解码器网络会读取这些编码并用另一种语言（比如英语）生成输出序列。 除了能力出色外，这种方法的好处是可以在该问题上训练单个端到端模型。 当将该方法用于图像描述时，编码器网络使用了深度卷积神经网络，解码器网络则是 LSTM 层的堆叠。 注意力机制编码器-解码器的一个局限性是使用了单个固定长度的表征来保存提取出的特征。 在机器翻译中，这个问题通过在更丰富的编码上开发的注意机制而得到了解决，从而让解码器可以学习在生成翻译中的每个词时应该注意哪里。 这种方法也已经被用于改进用于图像描述的编码器-解码器架构的表现水平——让解码器可以学习在生成描述中每个词时应该关注图像中的哪些部分。","link":"/2019/10/26/%E5%9B%BE%E7%89%87%E7%94%9F%E6%88%90%E6%96%87%E6%9C%AC%E6%8F%8F%E8%BF%B0/"},{"title":"机器学习面试准备","text":"一、前言为了面试，总结一下之前使用过的模型以及一些面试常问的问题。 二、相关模型2.1 MobileNets MobileNets are based on a streamlined architecture that uses depth-wise separable convolutions to build light weight deep neural networks. ----MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications MobileNets从字面上很好理解它想达到的效果，也就是做到”Mobile”，在一系列CNN变体中，模型一步步加深，直到ResNet，其网络层已达到152层，巨大的计算存储开销使得这些网络不能很好得应用于例如嵌入式等低功耗领域，因此引出MobileNets，其由Google于2017年提出，其优点在于使用 深度可分离卷积(depthwise separable convolutions) ，因此相比于使用一般卷机的网络结构，可以显著降低参数个数。 深度可分离卷积 深度可分离卷积在AlexNet已经有所应用，只是当时是为了解决在GPU上的训练问题，AlexNet无法放入单个GPU中进行训练，因此通过分离卷积，将conv2层设置group=2，把网络放在两个GPU上进行训练。深度可分离卷积**将标准卷积分解为深度卷积(depthwise convolution)和1x1卷积(在论文中称为pointwise convolution)**，并可证明这种分离方式可以降低计算量与模型大小。 设卷积的输入为F($D_F\\times D_F\\times M$)，stride=padding=1，输出为G($D_F\\times D_F\\times N$)。深度可分离卷积共分为两步：深度卷积为每个输入通道应用单个滤波器，并利用1x1卷积将深度卷积的输出进行线性结合。对于一个滤波器的深度卷积，卷积过程中第m个通道的output为： $$ \\hat{G}{k,l,m}=\\sum{i,j}\\hat{K}{i,j,m}\\cdot F{k-1+i,l-1+j,m}, $$ 其中，卷积核K($ D_K \\times D_K \\times M $)中的每个通道分别与输入通道分别相乘，可以看作少了标准卷积对每个通道求和。在这里，将每个通道联系起来的任务就交给了1x1卷积。1x1卷积将不同的通道求和，以收集每个点的特征。因此，通过深度卷积，我们得到的输出维度为$ D_K\\times D_K \\times N \\times M $，其中$N$为滤波器的个数，然后通过1x1卷积，我们得到的输出维度为$ D_K\\times D_K\\times N $的输出，与标准卷积得到的结果维度相同。 因此，在MobileNet中，将普通卷积替换为了深度卷积，提升了运行效率，其中： ​ 普通卷积：3x3 Conv -&gt; BN -&gt; ReLU; ​ 深度卷积：3x3 Depthwise Conv -&gt; BN -&gt; ReLU -&gt; 1x1 Conv -&gt; BN -&gt; ReLU. （1）若为标准卷积，卷积核为K($D_K\\times D_K \\times M\\times N$)，$M$为input channel个数，$N$为output channel个数，其计算成本为： $$ D_K\\cdot D_K\\cdot M\\cdot N\\cdot D_F. $$ （2）若为深度可分离卷积，设一个卷积核为K($D_K\\times D_K \\times M \\times N$)，$M$为input channel个数，N为output channel个数，其计算成本为： Depthwise : $$ D_K\\cdot D_K\\cdot M\\cdot D_F\\cdot D_F; $$ Pointwise：$M\\cdot N\\cdot D_F \\cdot D_F.$ 则现在的计算量是更换之前的 $$ \\frac{ D_K\\cdot D_K\\cdot M\\cdot D_F \\cdot D_F+M\\cdot N\\cdot D_F \\cdot D_F}{ D_K\\cdot D_K\\cdot M\\cdot N\\cdot D_F }=\\frac{1}{N}+\\frac{1}{D_K^2}. $$ 因此可以看到相比普通卷积，计算量有所下降。 在MobileNet除了有V1，还有V2版本，MobileNet V1有如下两个缺点： （1）易发生特征退化的问题，经过实验发现，当输入特征维数较低时，当输出后使用ReLU，得到输出之后再利用广义逆矩阵映射回原维度时，数据坍塌。 （2）使用ReLU作为激活函数时，如果输出为0，则梯度为0，因此后续迭代无法改变此节点的值，当网络中存在一定量的梯度为0的结点后，则会对整个网络造成影响，这在维度较低的情况下尤为明显，而通过ResNet的结构复用，可以很大程度上缓解这种特征退化问题。通过跳过一些梯度为0的结点，使得网络整体参数可以继续更新。 因此MobileNet采用Inverted residual block结构，首先使用1x1卷积对输入维度进行提升，然后再接ReLU，减少对特征的破坏，并利用残差连接降低特征退化的影响。 ​ Inverted residual block： ​ C1:1x1 Conv(ReLU) -&gt; 3x3 DWise Conv(ReLU) -&gt; C2:1x1 Conv(Linear) -&gt; add(C1,C2); ​ 1x1 Conv(ReLU) -&gt; 3x3 DWise Conv(ReLU), stride=2 -&gt; conv 1x1 Conv(Linear). 2.2 tinyYOLO（未完待续…","link":"/2019/04/16/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E9%9D%A2%E8%AF%95%E5%87%86%E5%A4%87/"},{"title":"集成学习和模型融合","text":"一、前言 众人拾柴火焰高。 ——XXX 在当前的机器学习算法竞赛中，模型融合方法已经十分普遍，在单学习器无法满足良好的学习效果的情况下，可以利用模型融合方法达到增强模型效果的作用。集成学习为《机器学习》(周志华)中的叫法，与模型融合类似，在这里一起进行介绍（以下模型融合即为集成学习）。在模型融合中，通过将多个学习器进行结合，以获得比单一学习器显著优越的泛化性能。本文将从什么是模型融合、何处需要使用模型融合、模型融合方法及模型融合实例进行介绍。 二、什么是模型融合 In statistics and machine learning, ensemble methods use multiple learning algorithms to obtain better predictive performance than could be obtained from any of the constituent learning algorithms alone. Unlike a statistical ensemble in statistical mechanics, which is usually infinite, a machine learning ensemble consists of only a concrete finite set of alternative models, but typically allows for much more flexible structure to exist among those alternatives. --wikipedia 在这段话中，介绍了模型融合的基本概念，模型融合指使用多种灵活多样(flexible structure)的学习算法集合获取更优的预测性能。所以说，模型融合可以看作是对单一学习算法的优化，可以改善单一算法预测准确率低、泛化性能差的缺点。 在模型融合中，被融合的部分称为”个体学习器”(individual learner)，个体学习器就是我们常见的一些机器学习算法 (e.g. C4.5 决策树、BP神经网络)，依照个体学习器之间的差异，模型融合方法可以分为： 基学习算法(base learning algorithm): 个体学习器是同质的(homogeneous); 组件学习算法(component learning algorithm): 个体学习器是异质的。 在模型融合的过程中，引出了不同的融合策略，如平均法(averaging)、投票法(voting)、学习法等，在第四大节将对这几种方法进行比较。 在了解模型融合前，我们首先需要理解模型融合为什么可以提升模型的预测准确度。其实可以很形象的理解，我们将其类比于美国的陪审团制度，在案件裁决过程中，陪审团需要作出裁决，在刑事案件中只有获得全数同意才可通过，在其余民事案件中只要多数同意就可以通过。陪审团的设立可以在一定程度上减轻法官裁决过程的不公正性以及其他因素对裁决的影响。而模型融合类似，每个个体学习器可以看作陪审团中的每位成员，而裁决过程可以看作模型融合的过程，而最终裁决结果的判断则可以看成不同融合策略。 下面从公式角度考虑模型融合对预测效果的提升，考虑一个二分类问题 $ y \\in {-1,+1} $ 和真实函数(数据输入和真实输出的映射)$ f $，假定每个分类器的错误率为$ \\epsilon $，即对每个分类器$ h_i $，有 $$ P(h_i(x)\\ne f(x))=\\epsilon. $$ 假设融合策略为简单投票法(即超过半数即为最后结果)，那么分类结果中预测正确的分类器个数$ H $为 $$ H(x)=\\sum_{i=1}^Th_i(x). $$ 即统计所有分类器的结果，若超过半数预测为1，即为1，否则为0。则对模型融合后的整体模型，其错误率类似于$i$重伯努利随机事件($i=1,2,…,k$)的求和(因为当分类器预测正确的个数为1，2，3直到n/2时，简单投票法均将输出错误结果)，即 $$ P(H(n)\\le k)=\\sum_{i=0}^kC_n^i(1-\\epsilon-in)^i\\epsilon^{n-i} $$ 在这里需要简单介绍一下Hoeffding不等式，其详细介绍见此链接。Hoeffding不等式可以用于计算一个算法的泛化误差上届，即随机变量的和与期望偏差的概率上届，可以理解为计算预测错误的概率最大可能值。通过衡量不同算法间的泛化误差上届，可以比较不同算法的优劣。Hoeffding的具体证明方法不再阐述，设正确预测的概率为$ p $，对于$n$个学习器，则预测正确次数的期望值为$ n*p $，则正确预测的次数不超过$k$次的概率为： $$ P(H(n)\\le k)=\\sum_{i=0}^kC^i_np^i(1-p)^{n-i}. $$ 而对某一$\\varepsilon&gt;0$当$k=(p-\\varepsilon)$时，有Hoeffding不等式 $$ P(H(n)\\le(p-\\varepsilon)n)\\le e^{-2\\varepsilon^2n}.$$ 由于使用简单投票法，则当基学习器预测正确个数小于$\\frac{n}{2}$时，融合模型输出结果错误，因此取$k=\\frac{n}{2}$，则模型融合的错误率为 $$ P(sign(H(x))\\ne f(x))=P(H(n)\\le\\frac{n}{2}) $$ $$ =\\sum_{i=0}^{\\frac{n}{2}}C_n^i(1-\\epsilon)^i\\epsilon^{n-i} $$ $$ \\le exp(-\\frac{n}{2}(1-2\\epsilon^2)) $$ 由上式我们可以看出，随着融合模型的分类器个数n增大，集成的错误率在呈指数级的下降，并最终趋于0。","link":"/2019/04/13/%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0%E5%92%8C%E6%A8%A1%E5%9E%8B%E8%9E%8D%E5%90%88/"}],"tags":[{"name":"Algorithms","slug":"Algorithms","link":"/tags/Algorithms/"},{"name":"Distributed System","slug":"Distributed-System","link":"/tags/Distributed-System/"},{"name":"自然语言处理","slug":"自然语言处理","link":"/tags/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/"},{"name":"图像处理","slug":"图像处理","link":"/tags/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/"},{"name":"图像特征提取","slug":"图像特征提取","link":"/tags/%E5%9B%BE%E5%83%8F%E7%89%B9%E5%BE%81%E6%8F%90%E5%8F%96/"},{"name":"语言模型","slug":"语言模型","link":"/tags/%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/"},{"name":"项目","slug":"项目","link":"/tags/%E9%A1%B9%E7%9B%AE/"},{"name":"面试","slug":"面试","link":"/tags/%E9%9D%A2%E8%AF%95/"},{"name":"集成学习","slug":"集成学习","link":"/tags/%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0/"},{"name":"竞赛","slug":"竞赛","link":"/tags/%E7%AB%9E%E8%B5%9B/"}],"categories":[{"name":"自然语言处理","slug":"自然语言处理","link":"/categories/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/"},{"name":"图像","slug":"图像","link":"/categories/%E5%9B%BE%E5%83%8F/"},{"name":"机器学习基础","slug":"机器学习基础","link":"/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/"}],"pages":[{"title":"Hi, I&#39;m Zhe Wang!","text":"Greeting! I’m Zhe Wang. Currently, I’m a graduate student majoring in Electrical and Computer Engineering at the University of Illinois at Urbana-Champaign. I first became interested in computers during middle school. I learned how to deal with them by searching the Internet, such as using FTP to access shared files. I also found ways to make tasks easier, such as running commands to shut the computer down every day after school automatically. I was attracted to computer science through this experience. I borrowed my brother’s teaching material from his university and started to learn the C Language and the basics of computer architecture. These experiences strengthened my goal to become a computer engineer in the future. Work ExperienceI have one year of experience as a full-time software engineer in the WeChat group of Tencent Technology. In my short time there, I’ve already contributed to two main projects of the company, WeChat for Mac and WeChat for Car. These two kinds of software have nearly 5 million users. WeChat for Mac https://mac.weixin.qq.com/?lang=en A Chinese multi-purpose instant messaging, social media Mac app. Provide text messaging, hold-to-talk voice messaging, broadcast (one-to-many) messaging, video conferencing, video games, sharing of photographs and videos, and location sharing. C++ Cocoa Unix Swift SQLite CGI Protobuf BlueKing CI WeChat for Car https://car.weixin.qq.com/#/ Interact mainly by voice, without tapping and touching to operate the application. In the driving scenario, users can always focus on driving. By using the steering wheel buttons, drivers can quickly wake up WeChat for Car, broadcast, reply to messages, answer and hang up voice calls, and safely communicate with their friends without taking their hands off the steering wheel. Java Android ADB I am honored as the Good+ Contributor in Tencent (About 20%). I think the reason is I am open to anything new. I analyzed and optimized the full-text search code in SQLite to let the user search faster for history messages. By optimizing the source code, the search speed upgraded about 20 times. And the size of the database was reduced by about 10%. I also implemented a scalable database structure and local data service of WeChat Social Networking Services using Swift with facade design pattern and RxSwift to handle asynchronous requests and data flow. In addition, I optimized file download and upload logic and support for large file transfer with Mars framework (https://github.com/Tencent/mars), a cross-platform network library, and utilized CGI to interact with the backend and Protocol Buffers to serialize data. Project Experience SoccerGod https://github.com/Mr-Wang119/BugFree SoccerGod is a full-stack website using Spring Boot and React.js. Users can browse news, view teams and players, post topics and comments, and predict results to earn points. RESTful APIs Spring Boot MySQL MongoDB Axios Python Google Cloud Platform Nginx Maven Jenkin Distributed Deposit and Transfer System based on ISIS Algorithm https://github.com/Mr-Wang119/isis Distributed Deposit and Transfer System is a distributed system of multiple processes that maintain accounts and transactions. We use the ISIS algorithm to satisfy the requirement of total ordering and build a reliable multicast through implementing the reliable multicast algorithm. TCP errors are captured to detect failures. Golang Standard Go Project Layout Distributed System ISIS Algorithm Reliable Multicast Algorithm Total Ordering Fault Tolerance Socket TCP I am also interested in distributed system areas. I have read several articles about distributed file and computing systems, such as Google File System, Big Table, Kafka, TAO, etc. The simplicity and efficacy impressed me a lot. I hope to build the same one via careful design and knowledge of related areas. I am also taking related courses and building a distributed Key-Value database system with high reliability, scalability, and consistency. Also, I am implementing a Bitcoin client using Rust with self-designed Blocks. I am actively looking for a summer internship in the US. Contact Me Email：wangzhe1109@outlook.com Resume: https://github.com/Mr-Wang119/resume/blob/dev/ZheWang-UIUC.pdf","link":"/about/index.html"}]}